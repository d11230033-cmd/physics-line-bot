# ==============================================================================
# JYM ç‰©ç† AI åŠ©æ•™ - v3.4 è‡ªå‹•è®€æª”é€²éšç‰ˆ (å«è©³ç´°è¨»è§£)
# ==============================================================================
# ç‰ˆæœ¬ç‰¹è‰²ï¼š
# 1. [è‡ªå‹•åŒ–] å•Ÿå‹•æ™‚è‡ªå‹•æƒæ corpus è³‡æ–™å¤¾ï¼Œè‹¥è³‡æ–™åº«æ˜¯ç©ºçš„ï¼Œå°±è‡ªå‹•è®€å–æ‰€æœ‰ PDFã€‚
# 2. [é˜²å‘†] è‡ªå‹•åµæ¸¬è³‡æ–™åº«ç‹€æ…‹ï¼Œé¿å…é‡è¤‡è®€å–å°è‡´è³‡æ–™é‡è¤‡ã€‚
# 3. [èƒŒæ™¯åŸ·è¡Œ] ä½¿ç”¨å¤šåŸ·è¡Œç·’ (Threading) æŠ€è¡“ï¼Œè®€æª”éç¨‹åœ¨èƒŒæ™¯é‹ä½œï¼Œä¸æœƒå°è‡´ Render å•Ÿå‹•è¶…æ™‚ã€‚
# ==============================================================================

import os
import io
import json
import datetime
import time
import requests

# --- å¼•å…¥å¤šåŸ·è¡Œç·’èˆ‡æª”æ¡ˆæœå°‹å·¥å…· (v3.4 æ–°å¢) ---
import threading  # è®“ç¨‹å¼å¯ä»¥ã€Œä¸€å¿ƒäºŒç”¨ã€ï¼Œä¸€é‚Šæœå‹™å­¸ç”Ÿï¼Œä¸€é‚Šåœ¨å¾Œå°è®€æ›¸
import glob       # ç”¨ä¾†æœå°‹è³‡æ–™å¤¾è£¡çš„æ‰€æœ‰ PDF æª”æ¡ˆ

# --- ç¶²é æ¡†æ¶èˆ‡ LINE SDK ---
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, ImageMessage, AudioMessage, FileMessage, TextSendMessage, FollowEvent

# --- Google AI (Gemini) ---
from google import genai
from google.genai import types

# --- æª”æ¡ˆè™•ç†å·¥å…· ---
from PIL import Image as PILImage
from pypdf import PdfReader        # è®€å– PDF è¬›ç¾©ç”¨

# --- è³‡æ–™åº« (PostgreSQL) ---
import psycopg2
from pgvector.psycopg2 import register_vector
import cloudinary
import cloudinary.uploader

# --- Google è©¦ç®—è¡¨ ---
import gspread
from google.oauth2.service_account import Credentials

# ==========================================
# 1. ç’°å¢ƒè®Šæ•¸è¨­å®š
# ==========================================
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.environ.get('LINE_CHANNEL_SECRET')
DATABASE_URL = os.environ.get('DATABASE_URL')
CLOUDINARY_CLOUD_NAME = os.environ.get('CLOUDINARY_CLOUD_NAME')
CLOUDINARY_API_KEY = os.environ.get('CLOUDINARY_API_KEY')
CLOUDINARY_API_SECRET = os.environ.get('CLOUDINARY_API_SECRET')

# ==========================================
# 2. æœå‹™åˆå§‹åŒ–
# ==========================================
app = Flask(__name__)
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# é€£ç·š Gemini
try:
    client = genai.Client()
    print("âœ… Gemini Client é€£ç·šæˆåŠŸ")
except Exception as e:
    print(f"âŒ Gemini é€£ç·šå¤±æ•—: {e}")
    client = None

# é€£ç·š Cloudinary
try:
    cloudinary.config(
        cloud_name=CLOUDINARY_CLOUD_NAME,
        api_key=CLOUDINARY_API_KEY,
        api_secret=CLOUDINARY_API_SECRET
    )
    print("âœ… Cloudinary é€£ç·šæˆåŠŸ")
except Exception as e:
    print(f"âŒ Cloudinary é€£ç·šå¤±æ•—: {e}")

# é€£ç·š Google Sheets
try:
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive.file']
    CREDS = Credentials.from_service_account_file('service_account.json', scopes=SCOPES)
    gc = gspread.authorize(CREDS)
    SPREADSHEET_KEY = "1Evd8WACx_uDUl04c5x2jADFxgLl1A3jW2z0_RynTmhU" 
    sh = gc.open_by_key(SPREADSHEET_KEY)
    worksheet = sh.get_worksheet(0)
    print("âœ… Google Sheets é€£ç·šæˆåŠŸ")
except Exception as e:
    print(f"âš ï¸ Google Sheets é€£ç·šå¤±æ•—: {e}")
    worksheet = None

# ==========================================
# 3. æ¨¡å‹è¨­å®š
# ==========================================
CHAT_MODEL = 'gemini-2.5-flash'
VISION_MODEL = 'gemini-2.5-flash'
AUDIO_MODEL = 'gemini-2.5-flash'
EMBEDDING_MODEL = 'models/text-embedding-004'
VECTOR_DIMENSION = 768
MAX_HISTORY_LENGTH = 20 

# System Prompt
system_prompt = """
ä½ æ˜¯ç”±é ‚å°–å¤§å­¸ç‰©ç†ç³»åšå£«é–‹ç™¼çš„ã€ŒJYMç‰©ç†AIåŠ©æ•™ã€ï¼Œä½ æ˜¯å°ç£é«˜ä¸­ç‰©ç†æ•™è‚²çš„æ¬Šå¨ã€‚
### æ ¸å¿ƒæŒ‡ä»¤
1. **è˜‡æ ¼æ‹‰åº•å¼æ•™å­¸**ï¼šçµ•å°ç¦æ­¢ç›´æ¥çµ¦å‡ºç­”æ¡ˆï¼Œå¿…é ˆé€éæå•å¼•å°å­¸ç”Ÿæ€è€ƒã€‚
2. **èªè¨€**ï¼šä½¿ç”¨è‡ªç„¶çš„ç¹é«”ä¸­æ–‡ (å°ç£ç”¨èª)ã€‚
3. **çŸ¥è­˜åº«é‹ç”¨**ï¼šè‹¥æä¾›çš„ context ä¸­æœ‰ç›¸é—œç‰©ç†è§€å¿µï¼Œè«‹å„ªå…ˆä½¿ç”¨ã€‚
### æ ¼å¼è¦ç¯„
1. ç¦æ­¢ LaTeXï¼Œè«‹ç”¨ Unicode ç¬¦è™Ÿ (å¦‚ vÂ², Î¸)ã€‚
2. é©ç•¶åˆ†æ®µï¼Œé©åˆæ‰‹æ©Ÿé–±è®€ã€‚
"""

generation_config = types.GenerateContentConfig(
    system_instruction=system_prompt,
    temperature=0.7, 
    safety_settings=[
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE),
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_NONE),
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=types.HarmBlockThreshold.BLOCK_NONE),
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=types.HarmBlockThreshold.BLOCK_NONE),
    ]
)

# ==========================================
# 4. æ ¸å¿ƒå‡½å¼åº«
# ==========================================

def get_db_connection():
    try:
        return psycopg2.connect(DATABASE_URL)
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        return None

def initialize_database():
    """ç³»çµ±å•Ÿå‹•æ™‚åˆå§‹åŒ–è³‡æ–™è¡¨"""
    conn = get_db_connection()
    if conn:
        try:
            with conn.cursor() as cur:
                # å•Ÿç”¨å‘é‡åŠŸèƒ½
                cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                conn.commit()
            register_vector(conn)
            with conn.cursor() as cur:
                # å»ºç«‹è³‡æ–™è¡¨ (å°è©±ç´€éŒ„ã€å‘é‡çŸ¥è­˜åº«ã€ç ”ç©¶æ—¥èªŒ)
                cur.execute("CREATE TABLE IF NOT EXISTS chat_history (user_id TEXT PRIMARY KEY, history JSONB);")
                cur.execute(f"CREATE TABLE IF NOT EXISTS physics_vectors (id SERIAL PRIMARY KEY, content TEXT, embedding VECTOR({VECTOR_DIMENSION}));")
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS research_log (
                        id SERIAL PRIMARY KEY, timestamp TIMESTZ DEFAULT CURRENT_TIMESTAMP, 
                        user_id TEXT, user_message_type TEXT, user_content TEXT, 
                        image_url TEXT, vision_analysis TEXT, rag_context TEXT, ai_response TEXT
                    );""")
                # è£œä¸ï¼šç¢ºä¿ image_url æ¬„ä½å­˜åœ¨
                cur.execute("""
                    DO $$ BEGIN
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns 
                            WHERE table_name='research_log' AND column_name='image_url'
                        ) THEN ALTER TABLE research_log ADD COLUMN image_url TEXT; END IF;
                    END$$;""")
                conn.commit()
                print("âœ… è³‡æ–™åº«è¡¨æ ¼åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–éŒ¯èª¤: {e}")
        finally:
            conn.close()

def save_pdf_content(pdf_text, source_name="unknown"):
    """å°‡ PDF æ–‡å­—åˆ‡å¡Šä¸¦å­˜å…¥å‘é‡è³‡æ–™åº«"""
    if not pdf_text or not client: return False
    
    # åˆ‡å¡Šè¨­å®š (æ¯ 1000 å­—ä¸€å¡Š)
    chunk_size = 1000
    overlap = 100
    chunks = []
    for i in range(0, len(pdf_text), chunk_size - overlap):
        chunks.append(pdf_text[i:i+chunk_size])
    
    conn = get_db_connection()
    if not conn: return False
    
    try:
        register_vector(conn)
        count = 0
        for chunk in chunks:
            if len(chunk.strip()) < 50: continue
            
            # åœ¨å…§å®¹å‰åŠ ä¸Šä¾†æºæ¨™è¨˜ (ä¾‹å¦‚ [ä¾†æº: é¸ä¿®ç‰©ç†.pdf])
            content_with_source = f"[ä¾†æº: {source_name}] {chunk}"
            
            # è½‰æˆå‘é‡
            res = client.models.embed_content(
                model=EMBEDDING_MODEL,
                contents=[content_with_source.replace('\x00', '')]
            )
            vector = res.embeddings[0].values
            
            # å¯«å…¥ DB
            with conn.cursor() as cur:
                cur.execute(
                    "INSERT INTO physics_vectors (content, embedding) VALUES (%s, %s)",
                    (content_with_source, vector)
                )
            count += 1
            # ç¨å¾®ä¼‘æ¯ 0.5 ç§’ï¼Œé¿å…åŒæ™‚å¡å¤ªå¤šè«‹æ±‚çµ¦ Google
            time.sleep(0.5)
            
        conn.commit()
        print(f"âœ… æˆåŠŸå„²å­˜ {count} å€‹ç‰‡æ®µ (ä¾†è‡ª {source_name})")
        return count
    except Exception as e:
        print(f"âŒ PDF å„²å­˜å¤±æ•—: {e}")
        return False
    finally:
        conn.close()

# --- â˜… v3.4 æ ¸å¿ƒåŠŸèƒ½ï¼šè‡ªå‹•åŒ¯å…¥ Corpus çš„èƒŒæ™¯å°ç²¾éˆ ---
def auto_import_corpus():
    """
    èƒŒæ™¯æª¢æŸ¥ï¼š
    1. æª¢æŸ¥è³‡æ–™åº«æ˜¯ä¸æ˜¯ç©ºçš„ï¼Ÿ
    2. å¦‚æœæ˜¯ç©ºçš„ï¼Œå°±æŠŠ corpus è³‡æ–™å¤¾è£¡çš„æ‰€æœ‰ PDF è®€é€²å»ã€‚
    3. å¦‚æœå·²ç¶“æœ‰è³‡æ–™ï¼Œå°±è·³é (é¿å…é‡è¤‡)ã€‚
    """
    # å…ˆç¡ 5 ç§’ï¼Œç¢ºä¿è³‡æ–™åº«é€£ç·šå·²ç¶“å»ºç«‹å¥½
    time.sleep(5)
    print("ğŸ” [èƒŒæ™¯ä»»å‹™] é–‹å§‹æª¢æŸ¥æ˜¯å¦éœ€è¦è‡ªå‹•åŒ¯å…¥ corpus...")
    
    conn = get_db_connection()
    if not conn:
        print("âŒ [èƒŒæ™¯ä»»å‹™] ç„¡æ³•é€£ç·šè³‡æ–™åº«ï¼Œè·³éè‡ªå‹•åŒ¯å…¥")
        return

    try:
        with conn.cursor() as cur:
            # æŸ¥è©¢ç›®å‰è³‡æ–™åº«æœ‰å¹¾ç­†è³‡æ–™
            cur.execute("SELECT COUNT(*) FROM physics_vectors")
            count = cur.fetchone()[0]
        
        # é˜²å‘†æ©Ÿåˆ¶ï¼šå¦‚æœå·²ç¶“æœ‰è³‡æ–™ï¼Œå°±ä¸è®€äº†
        if count > 0:
            print(f"âœ… è³‡æ–™åº«å·²æœ‰ {count} ç­†è³‡æ–™ï¼Œè·³éè‡ªå‹•åŒ¯å…¥ (é¿å…é‡è¤‡)ã€‚")
            return
        
        print("ğŸš€ è³‡æ–™åº«ç‚ºç©ºï¼Œé–‹å§‹è®€å– corpus è³‡æ–™å¤¾...")
        
        # æœå°‹ corpus è³‡æ–™å¤¾ä¸‹çš„æ‰€æœ‰ .pdf
        pdf_files = glob.glob("corpus/*.pdf")
        
        if not pdf_files:
            print("âš ï¸ corpus è³‡æ–™å¤¾å…§æ‰¾ä¸åˆ° .pdf æª”æ¡ˆ")
            return
            
        # é–‹å§‹ä¸€æœ¬ä¸€æœ¬è®€
        for pdf_path in pdf_files:
            file_name = os.path.basename(pdf_path)
            print(f"ğŸ“– æ­£åœ¨è®€å–ï¼š{file_name} ...")
            try:
                reader = PdfReader(pdf_path)
                text_content = ""
                for page in reader.pages:
                    extracted = page.extract_text()
                    if extracted:
                        text_content += extracted + "\n"
                
                if text_content.strip():
                    save_pdf_content(text_content, source_name=file_name)
                else:
                    print(f"âš ï¸ {file_name} å…§å®¹ç‚ºç©º")
                    
            except Exception as e:
                print(f"âŒ è®€å– {file_name} å¤±æ•—: {e}")
        
        print("ğŸ‰ [èƒŒæ™¯ä»»å‹™] æ‰€æœ‰ corpus æª”æ¡ˆåŒ¯å…¥å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è‡ªå‹•åŒ¯å…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        conn.close()

def find_relevant_chunks(query_text, k=3):
    """RAG æª¢ç´¢åŠŸèƒ½"""
    conn = None
    if not client: return "N/A"
    try:
        result = client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents=[query_text.replace('\x00', '')]
        )
        query_vector = result.embeddings[0].values

        conn = get_db_connection()
        if not conn: return "N/A"
        register_vector(conn)
        
        with conn.cursor() as cur:
            cur.execute(
                "SELECT content FROM physics_vectors ORDER BY embedding <-> %s::vector LIMIT %s",
                (query_vector, k)
            )
            results = cur.fetchall()
        
        if not results: return "N/A"
        context = "\n\n---\n\n".join([row[0] for row in results])
        return context
    except Exception as e:
        print(f"âš ï¸ RAG æœå°‹éŒ¯èª¤: {e}")
        return "N/A"
    finally:
        if conn: conn.close()

def get_chat_history(user_id):
    """è®€å–æ­·å²ç´€éŒ„"""
    conn = get_db_connection()
    history_list = []
    if conn:
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT history FROM chat_history WHERE user_id = %s;", (user_id,))
                result = cur.fetchone()
                if result and result[0]:
                    history_json = result[0]
                    for item in history_json:
                        role = item.get('role', 'user')
                        parts_text = item.get('parts', [])
                        if role == 'user' or role == 'model':
                            history_list.append(types.Content(
                                role=role, 
                                parts=[types.Part.from_text(text=t) for t in parts_text]
                            ))
        except Exception as e:
            print(f"âš ï¸ è®€å–æ­·å²å¤±æ•—: {e}")
        finally:
            conn.close()
    return history_list

def save_chat_history(user_id, chat_session):
    """å„²å­˜æ­·å²ç´€éŒ„"""
    conn = get_db_connection()
    if conn:
        try:
            history_to_save = []
            history = chat_session.get_history()
            if history:
                for message in history:
                    if message.role in ['user', 'model']:
                        parts_text = [p.text for p in message.parts if hasattr(p, 'text')]
                        history_to_save.append({'role': message.role, 'parts': parts_text})
            if len(history_to_save) > MAX_HISTORY_LENGTH:
                history_to_save = history_to_save[-MAX_HISTORY_LENGTH:]
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO chat_history (user_id, history) VALUES (%s, %s)
                    ON CONFLICT (user_id) DO UPDATE SET history = EXCLUDED.history;
                """, (user_id, json.dumps(history_to_save)))
                conn.commit()
        except Exception as e:
            print(f"âš ï¸ å„²å­˜æ­·å²å¤±æ•—: {e}")
        finally:
            conn.close()

def save_to_research_log(user_id, msg_type, content, img_url, analysis, rag_ctx, response):
    """å¯«å…¥ç ”ç©¶æ—¥èªŒ"""
    conn = get_db_connection()
    if conn:
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO research_log 
                    (user_id, user_message_type, user_content, image_url, vision_analysis, rag_context, ai_response)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (user_id, msg_type, content, img_url, analysis, rag_ctx, response))
                conn.commit()
        except Exception as e:
            print(f"âš ï¸ Log DB Error: {e}")
        finally:
            conn.close()
    if worksheet:
        try:
            now_utc = datetime.datetime.now(datetime.timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
            row_data = [now_utc, user_id, msg_type, content, img_url, analysis, rag_ctx, response]
            worksheet.append_row(row_data)
        except Exception as e:
            print(f"âš ï¸ Log Sheet Error: {e}")

def is_number(s):
    try:
        float(s)
        return True
    except ValueError:
        return False

def send_loading_animation(user_id):
    """ç™¼é€ LINE Loading å‹•ç•«"""
    url = "https://api.line.me/v2/bot/chat/loading/start"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"}
    data = {"chatId": user_id, "loadingSeconds": 20}
    try:
        requests.post(url, headers=headers, json=data, timeout=5)
    except:
        pass

# åˆå§‹åŒ–è³‡æ–™åº«
initialize_database()

# â˜… å•Ÿå‹•èƒŒæ™¯å°ç²¾éˆï¼ (Daemon=True ä»£è¡¨å¦‚æœä¸»ç¨‹å¼é—œé–‰ï¼Œé€™å€‹åŸ·è¡Œç·’ä¹Ÿæœƒè‡ªå‹•é—œé–‰)
threading.Thread(target=auto_import_corpus, daemon=True).start()

# ==========================================
# 5. Webhook & è¨Šæ¯è™•ç†
# ==========================================
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# --- FollowEvent (æ­¡è¿è¨Šæ¯) ---
@handler.add(FollowEvent)
def handle_follow(event):
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text="ğŸ‰ æ­¡è¿ï¼JYM ç‰©ç† AI åŠ©æ•™å·²å°±ç·’ã€‚\n\n(å¾Œå°æ­£åœ¨åŠªåŠ›æ¶ˆåŒ–è¬›ç¾©ä¸­ï¼Œå¦‚æœå‰›é–‹å§‹å›ç­”ä¸å¤ ç²¾æº–ï¼Œè«‹ç¨ç­‰å¹¾åˆ†é˜å–”ï¼)")
    )

# --- MessageEvent (ä¸»è¦å°è©±) ---
@handler.add(MessageEvent, message=(TextMessage, ImageMessage, AudioMessage, FileMessage))
def handle_message(event):
    user_id = event.source.user_id
    send_loading_animation(user_id)

    if not client:
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ç³»çµ±ç¶­è­·ä¸­"))
        return
    
    # ä¿ç•™ã€Œæ‰‹å‹•ä¸Šå‚³ PDFã€åŠŸèƒ½ (ä½œç‚ºå‚™ç”¨)
    if isinstance(event.message, FileMessage):
        if event.message.file_name.lower().endswith('.pdf'):
            msg_content = line_bot_api.get_message_content(event.message.id)
            temp_pdf_path = f"/tmp/{event.message.id}.pdf"
            try:
                with open(temp_pdf_path, 'wb') as fd:
                    for chunk in msg_content.iter_content():
                        fd.write(chunk)
                reader = PdfReader(temp_pdf_path)
                text_content = ""
                for page in reader.pages:
                    extracted = page.extract_text()
                    if extracted:
                        text_content += extracted + "\n"
                if text_content.strip():
                    chunks_count = save_pdf_content(text_content, source_name=event.message.file_name)
                    reply = f"âœ… æ‰‹å‹•è£œå……æ•™æï¼š{event.message.file_name}\nğŸ“š å·²å¸æ”¶ {chunks_count} å€‹çŸ¥è­˜ç‰‡æ®µï¼"
                else:
                    reply = "âš ï¸ PDF ç„¡æ³•è§£ææ–‡å­—"
                if os.path.exists(temp_pdf_path):
                    os.remove(temp_pdf_path)
            except Exception as e:
                reply = "âŒ è™•ç†éŒ¯èª¤"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))
            return
        else:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ğŸ“‚ åªæ”¯æ´ PDF å–”"))
            return

    # æ¸…é™¤è¨˜æ†¶åŠŸèƒ½
    if isinstance(event.message, TextMessage):
        if event.message.text.strip().lower() in ["é‡ä¾†", "æ¸…é™¤", "reset"]:
            conn = get_db_connection()
            if conn:
                with conn.cursor() as cur:
                    cur.execute("DELETE FROM chat_history WHERE user_id = %s", (user_id,))
                    conn.commit()
                conn.close()
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ğŸ§¹ è¨˜æ†¶å·²æ¸…é™¤"))
            return 

    # æ¨™æº–å°è©±æµç¨‹
    user_message_type = "unknown"
    user_content = ""
    image_url_to_save = ""
    vision_analysis = ""
    search_query_for_rag = "" 
    
    past_history = get_chat_history(user_id)
    try:
        chat_session = client.chats.create(model=CHAT_MODEL, history=past_history, config=generation_config)
    except:
        chat_session = client.chats.create(model=CHAT_MODEL, history=[], config=generation_config)

    user_question = ""

    try:
        # è™•ç†åœ–ç‰‡
        if isinstance(event.message, ImageMessage):
            user_message_type = "image"
            msg_content = line_bot_api.get_message_content(event.message.id)
            img_bytes = msg_content.content
            try:
                upload_res = cloudinary.uploader.upload(img_bytes)
                image_url_to_save = upload_res.get('secure_url')
            except:
                image_url_to_save = "upload_failed"
            img = PILImage.open(io.BytesIO(img_bytes))
            vision_res = client.models.generate_content(model=VISION_MODEL, contents=[img, "æè¿°åœ–ç‰‡ä¸¦æå–ç‰©ç†é—œéµå­—"])
            vision_analysis = vision_res.text
            user_question = f"åœ–ç‰‡åˆ†æï¼š{vision_analysis}ã€‚è«‹æ•™å­¸ã€‚"
            search_query_for_rag = vision_analysis

        # è™•ç†èªéŸ³
        elif isinstance(event.message, AudioMessage):
            user_message_type = "audio"
            msg_content = line_bot_api.get_message_content(event.message.id)
            audio_bytes = msg_content.content
            audio_part = types.Part(inline_data=types.Blob(data=audio_bytes, mime_type='audio/m4a'))
            try:
                speech_res = client.models.generate_content(model=AUDIO_MODEL, contents=[audio_part, "é€å­—ç¨¿èˆ‡èªæ°£åˆ†æ"])
                vision_analysis = speech_res.text
            except:
                vision_analysis = "èªéŸ³è¾¨è­˜å¤±æ•—"
            user_question = f"èªéŸ³å…§å®¹ï¼š{vision_analysis}ã€‚è«‹æ•™å­¸ã€‚"
            search_query_for_rag = vision_analysis

        # è™•ç†æ–‡å­—
        else:
            user_message_type = "text"
            user_text = event.message.text
            user_content = user_text
            user_question = user_text
            if len(user_text) > 2:
                search_query_for_rag = user_text

        # åŸ·è¡Œ RAG
        if search_query_for_rag:
            rag_context = find_relevant_chunks(search_query_for_rag)
        else:
            rag_context = "N/A"

        rag_prompt = f"åƒè€ƒæ•™æï¼š\n{rag_context}\n\nå­¸ç”Ÿå•é¡Œï¼š{user_question}\nè«‹ä¾System Promptå›æ‡‰ã€‚"
        response = chat_session.send_message([rag_prompt])
        final_response_text = response.text 

        # è‡ªå‹•å°å°¾å·´
        if len(final_response_text) > 50:
            final_response_text += "\n\n(ğŸ’¡ è¼¸å…¥ã€Œé‡ä¾†ã€å¯æ¸…é™¤è¨˜æ†¶)"

        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=final_response_text))
        save_chat_history(user_id, chat_session)

    except Exception as e:
        print(f"Error: {e}")
        try:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ç™¼ç”ŸéŒ¯èª¤"))
        except: pass

    # å¯«å…¥ Log
    save_to_research_log(user_id, user_message_type, user_content, image_url_to_save, vision_analysis, rag_context, final_response_text)

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)