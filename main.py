# ==============================================================================
# JYM ç‰©ç† AI åŠ©æ•™ - v4.0 å…¨çŸ¥å…¨èƒ½æ•™æˆç‰ˆ (å«è©³ç´°è¨»è§£)
# ==============================================================================
# ğŸš€ ç‰ˆæœ¬é€²åŒ–é‡é»ï¼š
# 1. [æ™ºæ…§å¢é‡å­¸ç¿’] ç³»çµ±æœ‰ã€Œè¨˜æ†¶ã€ï¼Œå•Ÿå‹•æ™‚æœƒæ¯”å°ã€Œå·²è®€æ›¸å–®ã€ã€‚åªè®€æ–°æ›¸ï¼ŒèˆŠæ›¸ä¸é‡è¤‡è®€ï¼Œå•Ÿå‹•é€Ÿåº¦é£›å¿«ã€‚
# 2. [åŠ©æ•™æ§åˆ¶å°] æ‚¨æ˜¯ç®¡ç†å“¡ï¼åœ¨ LINE è¼¸å…¥ !status, !sync, !clear å¯ç›´æ¥æ“æ§å¾Œå°ã€‚
# 3. [ä¾†æºæ¨™è¨»] å›ç­”å•é¡Œæ™‚ï¼ŒAI æœƒåƒè€ƒä¸¦æ¨™è¨»è³‡æ–™ä¾†æº (ä¾‹å¦‚ï¼š[ä¾†æº: é¸ä¿®ç‰©ç†Ch1.pdf])ã€‚
# ==============================================================================

import os
import io
import json
import datetime
import time
import requests

# --- å¼•å…¥å¤šåŸ·è¡Œç·’èˆ‡æª”æ¡ˆæœå°‹å·¥å…· ---
import threading  # è®“ç¨‹å¼å¯ä»¥ã€Œä¸€å¿ƒäºŒç”¨ã€ï¼Œä¸€é‚Šæœå‹™å­¸ç”Ÿï¼Œä¸€é‚Šåœ¨å¾Œå°è®€æ›¸
import glob       # ç”¨ä¾†æœå°‹è³‡æ–™å¤¾è£¡çš„æ‰€æœ‰ PDF æª”æ¡ˆ

# --- ç¶²é æ¡†æ¶èˆ‡ LINE SDK ---
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, ImageMessage, AudioMessage, FileMessage, TextSendMessage, FollowEvent

# --- Google AI (Gemini) ---
from google import genai
from google.genai import types

# --- æª”æ¡ˆè™•ç†å·¥å…· ---
from PIL import Image as PILImage
from pypdf import PdfReader        # è®€å– PDF è¬›ç¾©ç”¨

# --- è³‡æ–™åº« (PostgreSQL) ---
import psycopg2
from pgvector.psycopg2 import register_vector # è™•ç†å‘é‡è³‡æ–™
import cloudinary
import cloudinary.uploader

# --- Google è©¦ç®—è¡¨ ---
import gspread
from google.oauth2.service_account import Credentials

# ==========================================
# 1. ç’°å¢ƒè®Šæ•¸è¨­å®š (å¾ Render å¾Œå°è®€å–)
# ==========================================
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.environ.get('LINE_CHANNEL_SECRET')
DATABASE_URL = os.environ.get('DATABASE_URL')
CLOUDINARY_CLOUD_NAME = os.environ.get('CLOUDINARY_CLOUD_NAME')
CLOUDINARY_API_KEY = os.environ.get('CLOUDINARY_API_KEY')
CLOUDINARY_API_SECRET = os.environ.get('CLOUDINARY_API_SECRET')

# ==========================================
# 2. æœå‹™åˆå§‹åŒ–
# ==========================================
app = Flask(__name__)
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# é€£ç·š Gemini
try:
    client = genai.Client()
    print("âœ… Gemini Client é€£ç·šæˆåŠŸ")
except Exception as e:
    print(f"âŒ Gemini é€£ç·šå¤±æ•—: {e}")
    client = None

# é€£ç·š Cloudinary (åœ–åºŠ)
try:
    cloudinary.config(
        cloud_name=CLOUDINARY_CLOUD_NAME,
        api_key=CLOUDINARY_API_KEY,
        api_secret=CLOUDINARY_API_SECRET
    )
    print("âœ… Cloudinary é€£ç·šæˆåŠŸ")
except Exception as e:
    print(f"âŒ Cloudinary é€£ç·šå¤±æ•—: {e}")

# é€£ç·š Google Sheets (ç ”ç©¶æ—¥èªŒ)
try:
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive.file']
    CREDS = Credentials.from_service_account_file('service_account.json', scopes=SCOPES)
    gc = gspread.authorize(CREDS)
    SPREADSHEET_KEY = "1Evd8WACx_uDUl04c5x2jADFxgLl1A3jW2z0_RynTmhU" 
    sh = gc.open_by_key(SPREADSHEET_KEY)
    worksheet = sh.get_worksheet(0)
    print("âœ… Google Sheets é€£ç·šæˆåŠŸ")
except Exception as e:
    print(f"âš ï¸ Google Sheets é€£ç·šå¤±æ•—: {e}")
    worksheet = None

# ==========================================
# 3. æ¨¡å‹è¨­å®š (System Prompt)
# ==========================================
CHAT_MODEL = 'gemini-2.5-flash'
VISION_MODEL = 'gemini-2.5-flash-image'
AUDIO_MODEL = 'gemini-2.5-flash'
EMBEDDING_MODEL = 'models/text-embedding-004'
VECTOR_DIMENSION = 768
MAX_HISTORY_LENGTH = 20 

system_prompt = """
ä½ æ˜¯ç”±é ‚å°–å¤§å­¸ç‰©ç†ç³»åšå£«é–‹ç™¼çš„ã€ŒJYMç‰©ç†AIåŠ©æ•™ã€ï¼Œä½ æ˜¯å°ç£é«˜ä¸­ç‰©ç†æ•™è‚²çš„æ¬Šå¨ã€‚
### æ ¸å¿ƒæŒ‡ä»¤
1. **è˜‡æ ¼æ‹‰åº•å¼æ•™å­¸**ï¼šçµ•å°ç¦æ­¢ç›´æ¥çµ¦å‡ºç­”æ¡ˆï¼Œå¿…é ˆé€éæå•å¼•å°å­¸ç”Ÿæ€è€ƒã€‚
2. **èªè¨€**ï¼šä½¿ç”¨è‡ªç„¶çš„ç¹é«”ä¸­æ–‡ (å°ç£ç”¨èª)ã€‚
3. **å¼•ç”¨æ¬Šå¨**ï¼šè‹¥ context ä¸­æœ‰æ•™æå…§å®¹ (æ¨™è¨»ç‚º [ä¾†æº: xxx])ï¼Œè«‹å‹™å¿…åƒè€ƒï¼Œä¸¦åœ¨å›ç­”ä¸­èåˆè©²è§€å¿µã€‚
### æ ¼å¼è¦ç¯„
1. ç¦æ­¢ LaTeXï¼Œè«‹ç”¨ Unicode ç¬¦è™Ÿ (å¦‚ vÂ², Î¸)ã€‚
2. é©ç•¶åˆ†æ®µï¼Œé©åˆæ‰‹æ©Ÿé–±è®€ã€‚
"""

generation_config = types.GenerateContentConfig(
    system_instruction=system_prompt,
    temperature=0.7, 
    safety_settings=[
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE),
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.BLOCK_NONE),
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=types.HarmBlockThreshold.BLOCK_NONE),
        types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=types.HarmBlockThreshold.BLOCK_NONE),
    ]
)

# ==========================================
# 4. æ ¸å¿ƒå‡½å¼åº« (è³‡æ–™åº«èˆ‡ RAG)
# ==========================================

def get_db_connection():
    try:
        return psycopg2.connect(DATABASE_URL)
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—: {e}")
        return None

def initialize_database():
    """ç³»çµ±å•Ÿå‹•æ™‚åˆå§‹åŒ–è³‡æ–™è¡¨ï¼Œç¢ºä¿è…¦è¢‹æ§‹é€ æ­£ç¢º"""
    conn = get_db_connection()
    if conn:
        try:
            with conn.cursor() as cur:
                # å•Ÿç”¨å‘é‡æ“´å……åŠŸèƒ½
                cur.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                conn.commit()
            register_vector(conn)
            with conn.cursor() as cur:
                # 1. å°è©±æ­·å²è¡¨
                cur.execute("CREATE TABLE IF NOT EXISTS chat_history (user_id TEXT PRIMARY KEY, history JSONB);")
                # 2. ç‰©ç†çŸ¥è­˜å‘é‡è¡¨
                cur.execute(f"CREATE TABLE IF NOT EXISTS physics_vectors (id SERIAL PRIMARY KEY, content TEXT, embedding VECTOR({VECTOR_DIMENSION}));")
                
                # â˜… v4.0 æ–°å¢ï¼šå·²è®€æ›¸å–®è¡¨ (ç”¨ä¾†è¨˜éŒ„å“ªæœ¬æ›¸å·²ç¶“è®€éäº†)
                cur.execute("CREATE TABLE IF NOT EXISTS imported_files (filename TEXT PRIMARY KEY, imported_at TIMESTZ DEFAULT CURRENT_TIMESTAMP);")
                
                # 3. ç ”ç©¶æ—¥èªŒè¡¨
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS research_log (
                        id SERIAL PRIMARY KEY, timestamp TIMESTZ DEFAULT CURRENT_TIMESTAMP, 
                        user_id TEXT, user_message_type TEXT, user_content TEXT, 
                        image_url TEXT, vision_analysis TEXT, rag_context TEXT, ai_response TEXT
                    );""")
                
                # è£œä¸ï¼šç¢ºä¿èˆŠç‰ˆè³‡æ–™åº«ä¹Ÿæœ‰ image_url æ¬„ä½
                cur.execute("""
                    DO $$ BEGIN
                        IF NOT EXISTS (
                            SELECT 1 FROM information_schema.columns 
                            WHERE table_name='research_log' AND column_name='image_url'
                        ) THEN ALTER TABLE research_log ADD COLUMN image_url TEXT; END IF;
                    END$$;""")
                
                conn.commit()
                print("âœ… è³‡æ–™åº« v4.0 æ¶æ§‹åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–éŒ¯èª¤: {e}")
        finally:
            conn.close()

def save_pdf_content(pdf_text, source_name="unknown"):
    """å°‡ PDF æ–‡å­—åˆ‡å¡Šä¸¦å­˜å…¥å‘é‡è³‡æ–™åº«ï¼Œä¸¦ç™»è¨˜åˆ°å·²è®€æ›¸å–®"""
    if not pdf_text or not client: return False
    
    chunk_size = 1000
    overlap = 100
    chunks = []
    for i in range(0, len(pdf_text), chunk_size - overlap):
        chunks.append(pdf_text[i:i+chunk_size])
    
    conn = get_db_connection()
    if not conn: return False
    
    try:
        register_vector(conn)
        count = 0
        for chunk in chunks:
            if len(chunk.strip()) < 50: continue
            
            # â˜… v4.0 ä¾†æºæ¨™è¨»ï¼šåœ¨å…§å®¹å‰åŠ ä¸Š [ä¾†æº: æª”å]ï¼Œæ–¹ä¾¿ AI å¼•ç”¨
            content_with_source = f"[ä¾†æº: {source_name}] {chunk}"
            
            res = client.models.embed_content(
                model=EMBEDDING_MODEL,
                contents=[content_with_source.replace('\x00', '')]
            )
            vector = res.embeddings[0].values
            
            with conn.cursor() as cur:
                cur.execute(
                    "INSERT INTO physics_vectors (content, embedding) VALUES (%s, %s)",
                    (content_with_source, vector)
                )
            count += 1
            time.sleep(0.3) # ç¨å¾®ä¼‘æ¯é¿å… API è¶…é€Ÿ
            
        # â˜… v4.0 é—œéµæ­¥é©Ÿï¼šç™»è¨˜é€™æœ¬æ›¸å·²ç¶“è®€éäº†ï¼
        with conn.cursor() as cur:
            cur.execute(
                "INSERT INTO imported_files (filename) VALUES (%s) ON CONFLICT (filename) DO UPDATE SET imported_at = CURRENT_TIMESTAMP",
                (source_name,)
            )
        
        conn.commit()
        print(f"âœ… æˆåŠŸå„²å­˜ {count} å€‹ç‰‡æ®µ (ä¾†è‡ª {source_name})")
        return count
    except Exception as e:
        print(f"âŒ PDF å„²å­˜å¤±æ•—: {e}")
        return False
    finally:
        conn.close()

# --- â˜… v4.0 æ ¸å¿ƒï¼šæ™ºæ…§å¢é‡å­¸ç¿’ç³»çµ± ---
def auto_import_corpus_v4():
    """
    èƒŒæ™¯ä»»å‹™ï¼š
    1. çœ‹çœ‹è³‡æ–™åº«è£¡å·²ç¶“æœ‰å“ªäº›æ›¸ (imported_files)ã€‚
    2. çœ‹çœ‹è³‡æ–™å¤¾è£¡æœ‰å“ªäº›æ›¸ (corpus/*.pdf)ã€‚
    3. æ‰¾å‡ºã€Œæ–°æ›¸ã€ä¸¦è®€å–ã€‚
    4. ç•¥éèˆŠæ›¸ï¼Œç¯€çœæ™‚é–“èˆ‡è³‡æºã€‚
    """
    time.sleep(3) # ç­‰å¾…ä¼ºæœå™¨ç©©å®š
    print("ğŸ” [v4.0 æ™ºæ…§åŒæ­¥] é–‹å§‹æª¢æŸ¥ corpus è³‡æ–™å¤¾...")
    
    conn = get_db_connection()
    if not conn:
        print("âŒ ç„¡æ³•é€£ç·šè³‡æ–™åº«ï¼Œè·³éåŒæ­¥")
        return

    try:
        # 1. å–å¾—è³‡æ–™åº«ã€Œå·²è®€æ›¸å–®ã€
        processed_files = set()
        with conn.cursor() as cur:
            cur.execute("SELECT filename FROM imported_files")
            rows = cur.fetchall()
            for row in rows:
                processed_files.add(row[0])
        
        print(f"ğŸ“š è³‡æ–™åº«ç›®å‰å·²æ”¶éŒ„ {len(processed_files)} æœ¬æ›¸ã€‚")

        # 2. æƒæç¡¬ç¢Ÿè³‡æ–™å¤¾
        pdf_files = glob.glob("corpus/*.pdf")
        if not pdf_files:
            print("âš ï¸ corpus è³‡æ–™å¤¾æ˜¯ç©ºçš„")
            return

        new_files_count = 0
        for pdf_path in pdf_files:
            file_name = os.path.basename(pdf_path)
            
            # â˜… æ™ºæ…§åˆ¤æ–·ï¼šå¦‚æœé€™æœ¬æ›¸åœ¨å·²è®€æ›¸å–®è£¡ï¼Œå°±è·³éï¼
            if file_name in processed_files:
                continue
            
            print(f"ğŸš€ ç™¼ç¾æ–°æ•™æï¼š{file_name}ï¼Œé–‹å§‹å¸æ”¶...")
            try:
                reader = PdfReader(pdf_path)
                text_content = ""
                for page in reader.pages:
                    extracted = page.extract_text()
                    if extracted:
                        text_content += extracted + "\n"
                
                if text_content.strip():
                    save_pdf_content(text_content, source_name=file_name)
                    new_files_count += 1
                else:
                    print(f"âš ï¸ {file_name} å…§å®¹ç‚ºç©º")
            except Exception as e:
                print(f"âŒ è®€å– {file_name} å¤±æ•—: {e}")
        
        if new_files_count == 0:
            print("âœ… æ‰€æœ‰æ•™æéƒ½å·²æ˜¯æœ€æ–°çš„ï¼Œç„¡éœ€æ›´æ–°ã€‚")
        else:
            print(f"ğŸ‰ æ›´æ–°å®Œæˆï¼å…±å¸æ”¶äº† {new_files_count} æœ¬æ–°è¬›ç¾©ã€‚")
            
    except Exception as e:
        print(f"âŒ è‡ªå‹•åŒ¯å…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        conn.close()

def find_relevant_chunks(query_text, k=3):
    """RAG æª¢ç´¢ï¼šæ‰¾å‡ºæœ€ç›¸é—œçš„ 3 å€‹çŸ¥è­˜ç‰‡æ®µ"""
    conn = None
    if not client: return "N/A"
    try:
        result = client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents=[query_text.replace('\x00', '')]
        )
        query_vector = result.embeddings[0].values

        conn = get_db_connection()
        if not conn: return "N/A"
        register_vector(conn)
        
        with conn.cursor() as cur:
            cur.execute(
                "SELECT content FROM physics_vectors ORDER BY embedding <-> %s::vector LIMIT %s",
                (query_vector, k)
            )
            results = cur.fetchall()
        
        if not results: return "N/A"
        context = "\n\n---\n\n".join([row[0] for row in results])
        return context
    except Exception as e:
        print(f"âš ï¸ RAG æœå°‹éŒ¯èª¤: {e}")
        return "N/A"
    finally:
        if conn: conn.close()

# --- æ­·å²ç´€éŒ„ & Log å·¥å…·å‡½å¼ ---
def get_chat_history(user_id):
    """è®€å–æ­·å²"""
    conn = get_db_connection()
    history_list = []
    if conn:
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT history FROM chat_history WHERE user_id = %s;", (user_id,))
                result = cur.fetchone()
                if result and result[0]:
                    history_json = result[0]
                    for item in history_json:
                        role = item.get('role', 'user')
                        parts_text = item.get('parts', [])
                        if role == 'user' or role == 'model':
                            history_list.append(types.Content(
                                role=role, 
                                parts=[types.Part.from_text(text=t) for t in parts_text]
                            ))
        except Exception as e: pass
        finally: conn.close()
    return history_list

def save_chat_history(user_id, chat_session):
    """å„²å­˜æ­·å²"""
    conn = get_db_connection()
    if conn:
        try:
            history_to_save = []
            history = chat_session.get_history()
            if history:
                for message in history:
                    if message.role in ['user', 'model']:
                        parts_text = [p.text for p in message.parts if hasattr(p, 'text')]
                        history_to_save.append({'role': message.role, 'parts': parts_text})
            if len(history_to_save) > MAX_HISTORY_LENGTH:
                history_to_save = history_to_save[-MAX_HISTORY_LENGTH:]
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO chat_history (user_id, history) VALUES (%s, %s)
                    ON CONFLICT (user_id) DO UPDATE SET history = EXCLUDED.history;
                """, (user_id, json.dumps(history_to_save)))
                conn.commit()
        except Exception as e: pass
        finally: conn.close()

def save_to_research_log(user_id, msg_type, content, img_url, analysis, rag_ctx, response):
    """å¯«å…¥ç ”ç©¶æ—¥èªŒ"""
    conn = get_db_connection()
    if conn:
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO research_log 
                    (user_id, user_message_type, user_content, image_url, vision_analysis, rag_context, ai_response)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (user_id, msg_type, content, img_url, analysis, rag_ctx, response))
                conn.commit()
        except Exception as e: pass
        finally: conn.close()
    if worksheet:
        try:
            now_utc = datetime.datetime.now(datetime.timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
            row_data = [now_utc, user_id, msg_type, content, img_url, analysis, rag_ctx, response]
            worksheet.append_row(row_data)
        except: pass

def send_loading_animation(user_id):
    """ç™¼é€ Loading å‹•ç•«"""
    url = "https://api.line.me/v2/bot/chat/loading/start"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"}
    data = {"chatId": user_id, "loadingSeconds": 20}
    try: requests.post(url, headers=headers, json=data, timeout=5)
    except: pass

# --- ç¨‹å¼å•Ÿå‹•ç¨‹åº ---
initialize_database()
# â˜… å•Ÿå‹• v4.0 æ™ºæ…§åŒæ­¥ (èƒŒæ™¯åŸ·è¡Œ)
threading.Thread(target=auto_import_corpus_v4, daemon=True).start()

# ==========================================
# 5. Webhook & è¨Šæ¯è™•ç†
# ==========================================
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

@handler.add(FollowEvent)
def handle_follow(event):
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text="ğŸ‘¨â€ğŸ« æ‚¨å¥½ï¼Œæˆ‘æ˜¯ JYM ç‰©ç† AI æ•™æˆ (v4.0)ã€‚\næˆ‘å·²å…·å‚™ã€Œå¢é‡å­¸ç¿’ã€èƒ½åŠ›ï¼Œæœƒè‡ªå‹•æ¶ˆåŒ–æ‚¨ä¸Šå‚³çš„æ–°è¬›ç¾©ã€‚\nè«‹éš¨æ™‚å‘æˆ‘æå•ï¼")
    )

@handler.add(MessageEvent, message=(TextMessage, ImageMessage, AudioMessage, FileMessage))
def handle_message(event):
    user_id = event.source.user_id
    send_loading_animation(user_id)

    # --- â˜… v4.0 åŠ©æ•™ç®¡ç†æŒ‡ä»¤å€ (Admin Commands) ---
    # é€™äº›æŒ‡ä»¤åªæœ‰çŸ¥é“çš„äººå¯ä»¥ç”¨ï¼Œç”¨ä¾†ç®¡ç†æ©Ÿå™¨äºº
    if isinstance(event.message, TextMessage):
        user_text = event.message.text.strip()
        
        # 1. æŸ¥è©¢ç‹€æ…‹ (è¼¸å…¥ !status)
        if user_text == "!status":
            conn = get_db_connection()
            status_msg = "ğŸ“Š åŠ©æ•™å·¥ä½œå ±å‘Šï¼š\n"
            if conn:
                with conn.cursor() as cur:
                    # æŸ¥ç‰‡æ®µæ•¸
                    cur.execute("SELECT COUNT(*) FROM physics_vectors")
                    vec_count = cur.fetchone()[0]
                    # æŸ¥å·²è®€æ›¸å–®
                    cur.execute("SELECT filename FROM imported_files")
                    files = cur.fetchall()
                conn.close()
                file_list = "\n".join([f"- {row[0]}" for row in files])
                status_msg += f"ğŸ§  çŸ¥è­˜åº«ç‰‡æ®µæ•¸ï¼š{vec_count}\nğŸ“š å·²å¸æ”¶æ›¸å–®ï¼š\n{file_list}"
            else:
                status_msg += "âŒ è³‡æ–™åº«é€£ç·šå¤±æ•—"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=status_msg))
            return

        # 2. å¼·åˆ¶åŒæ­¥ (è¼¸å…¥ !sync) - å¦‚æœä½ æƒ³å¼·åˆ¶å®ƒå†æƒæä¸€æ¬¡
        if user_text == "!sync":
            threading.Thread(target=auto_import_corpus_v4, daemon=True).start()
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ğŸš€ æ”¶åˆ°æŒ‡ä»¤ï¼æ­£åœ¨èƒŒæ™¯å¼·åˆ¶æƒææ–°è¬›ç¾©..."))
            return

        # 3. æ¸…ç©ºå¤§è…¦ (è¼¸å…¥ !clear) - å±éšªæ“ä½œï¼
        if user_text == "!clear":
            conn = get_db_connection()
            if conn:
                with conn.cursor() as cur:
                    cur.execute("TRUNCATE TABLE chat_history")
                    cur.execute("TRUNCATE TABLE physics_vectors")
                    cur.execute("TRUNCATE TABLE imported_files")
                    conn.commit()
                conn.close()
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âš ï¸ å·²åŸ·è¡Œï¼šå¤§è…¦å®Œå…¨æ ¼å¼åŒ–ã€‚æ‰€æœ‰çŸ¥è­˜èˆ‡è¨˜æ†¶å·²æ¸…ç©ºã€‚"))
            return

        # 4. æ¸…é™¤å°è©±è¨˜æ†¶ (è¼¸å…¥ é‡ä¾†) - é€™æ˜¯çµ¦ä¸€èˆ¬ä½¿ç”¨è€…æ¸…å°è©±ç”¨çš„
        if user_text.lower() in ["é‡ä¾†", "æ¸…é™¤", "reset"]:
            conn = get_db_connection()
            if conn:
                with conn.cursor() as cur:
                    cur.execute("DELETE FROM chat_history WHERE user_id = %s", (user_id,))
                    conn.commit()
                conn.close()
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ğŸ§¹ è¨˜æ†¶å·²æ¸…é™¤ï¼Œæˆ‘å€‘å¯ä»¥é‡æ–°é–‹å§‹äº†ã€‚"))
            return 

    # --- æ¨™æº–å°è©±æµç¨‹ (è‹¥éæŒ‡ä»¤ï¼Œå‰‡åŸ·è¡Œé€™è£¡) ---
    user_message_type = "unknown"
    user_content = ""
    image_url_to_save = ""
    vision_analysis = ""
    search_query_for_rag = "" 
    
    past_history = get_chat_history(user_id)
    try:
        chat_session = client.chats.create(model=CHAT_MODEL, history=past_history, config=generation_config)
    except:
        chat_session = client.chats.create(model=CHAT_MODEL, history=[], config=generation_config)

    user_question = ""

    try:
        # è™•ç†åœ–ç‰‡
        if isinstance(event.message, ImageMessage):
            user_message_type = "image"
            msg_content = line_bot_api.get_message_content(event.message.id)
            img_bytes = msg_content.content
            try:
                upload_res = cloudinary.uploader.upload(img_bytes)
                image_url_to_save = upload_res.get('secure_url')
            except:
                image_url_to_save = "upload_failed"
            img = PILImage.open(io.BytesIO(img_bytes))
            vision_res = client.models.generate_content(model=VISION_MODEL, contents=[img, "æè¿°åœ–ç‰‡ä¸¦æå–ç‰©ç†é—œéµå­—"])
            vision_analysis = vision_res.text
            user_question = f"åœ–ç‰‡åˆ†æï¼š{vision_analysis}ã€‚è«‹æ•™å­¸ã€‚"
            search_query_for_rag = vision_analysis

        # è™•ç†èªéŸ³
        elif isinstance(event.message, AudioMessage):
            user_message_type = "audio"
            msg_content = line_bot_api.get_message_content(event.message.id)
            audio_bytes = msg_content.content
            audio_part = types.Part(inline_data=types.Blob(data=audio_bytes, mime_type='audio/m4a'))
            try:
                speech_res = client.models.generate_content(model=AUDIO_MODEL, contents=[audio_part, "é€å­—ç¨¿èˆ‡èªæ°£åˆ†æ"])
                vision_analysis = speech_res.text
            except:
                vision_analysis = "èªéŸ³è¾¨è­˜å¤±æ•—"
            user_question = f"èªéŸ³å…§å®¹ï¼š{vision_analysis}ã€‚è«‹æ•™å­¸ã€‚"
            search_query_for_rag = vision_analysis

        # è™•ç†æ–‡å­—
        else: 
            user_message_type = "text"
            user_text = event.message.text
            user_content = user_text
            user_question = user_text
            if len(user_text) > 2:
                search_query_for_rag = user_text

        # åŸ·è¡Œ RAG çŸ¥è­˜æª¢ç´¢
        if search_query_for_rag:
            rag_context = find_relevant_chunks(search_query_for_rag)
        else:
            rag_context = "N/A"

        # çµ„åˆ Prompt (è¦æ±‚å¼•ç”¨ä¾†æº)
        rag_prompt = f"åƒè€ƒæ•™æï¼š\n{rag_context}\n\nå­¸ç”Ÿå•é¡Œï¼š{user_question}\nè«‹ä¾System Promptå›æ‡‰ï¼Œè‹¥æœ‰ä½¿ç”¨æ•™æè«‹æ¨™è¨»ä¾†æºã€‚"
        response = chat_session.send_message([rag_prompt])
        final_response_text = response.text 

        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=final_response_text))
        save_chat_history(user_id, chat_session)

    except Exception as e:
        print(f"Error: {e}")
        try:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âš ï¸ ç³»çµ±ç¹å¿™ä¸­ï¼Œè«‹ç¨å¾Œå†è©¦"))
        except: pass

    # å¯«å…¥ç ”ç©¶æ—¥èªŒ
    save_to_research_log(user_id, user_message_type, user_content, image_url_to_save, vision_analysis, rag_context, final_response_text)

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)